import re
from typing import List, Tuple
from langchain.schema import Document

def filter_documents(documents: List[Document], min_length: int = 100) -> Tuple[List[Document], List[Document]]:
    """
    æ¸…æ´—æ–‡æ¡£ï¼šè¿‡æ»¤å†…å®¹è¿‡çŸ­æˆ–åŒ…å«ä¹±ç çš„ Document å®ä¾‹ã€‚

    Args:
        documents (List[Document]): åŸå§‹æ–‡æ¡£åˆ—è¡¨ã€‚
        min_length (int): æ–‡æ¡£å†…å®¹çš„æœ€å°æœ‰æ•ˆå­—ç¬¦æ•°ï¼Œé»˜è®¤100ã€‚

    Returns:
        Tuple[List[Document], List[Document]]: 
            (clean_documents, filtered_documents)
            - clean_documents: æ¸…æ´—åçš„æœ‰æ•ˆæ–‡æ¡£åˆ—è¡¨ï¼›
            - filtered_documents: è¢«å‰”é™¤çš„æ— æ•ˆ/ä¹±ç æ–‡æ¡£åˆ—è¡¨ã€‚
    """
    clean_documents = []
    filtered_documents = []

    for doc in documents:
        content = doc.page_content.strip()

        # æ¡ä»¶1ï¼šå†…å®¹è¿‡çŸ­
        too_short = len(content) < min_length

        # æ¡ä»¶2ï¼šç–‘ä¼¼ä¹±ç ï¼ˆå¦‚è¿ç»­20ä¸ªéå­—æ¯æ•°å­—ç©ºæ ¼ï¼‰
        has_garbage = re.search(r'[^a-zA-Z0-9\s]{20,}', content[:500]) is not None

        if too_short or has_garbage:
            filtered_documents.append(doc)
        else:
            clean_documents.append(doc)
    
    print(f"\nğŸ“Š æ–‡æ¡£æ¸…æ´—å®Œæˆï¼š")
    print(f"  - åŸå§‹æ–‡æ¡£æ•°é‡ï¼š{len(documents)}")
    print(f"  - ä¿ç•™æœ‰æ•ˆæ–‡æ¡£ï¼š{len(clean_documents)}")
    print(f"  - å‰”é™¤æ— æ•ˆ/ä¹±ç æ–‡æ¡£ï¼š{len(filtered_documents)}")

    return clean_documents, filtered_documents